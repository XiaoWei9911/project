{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e801706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ger=pd.read_table('./German/german.data', header=None,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b3f21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colnames=['Status','Duration','History','Purpose','Amount','Savings','Employment','Installment%','Personal','Other','Residence','Property','Age','Plans','Housing','Existing','Job', 'People','Telephone','Foreign','Label']\n",
    "ger.columns=colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ae4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee94d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#normalize numerical, category:one hot\n",
    "ger_pre=ger.copy(deep=True)\n",
    "ger_pre=ger_pre.drop(columns=['Label'])\n",
    "numer_ger=StandardScaler().fit_transform(ger_pre.select_dtypes(include='int64'))\n",
    "numer_ger=pd.DataFrame(numer_ger,columns = ger_pre.select_dtypes(include='number').columns)\n",
    "#print(numer_ger)\n",
    "\n",
    "cate_ger=pd.get_dummies(ger_pre.select_dtypes(exclude='int64'))\n",
    "\n",
    "\n",
    "scale_ger=pd.concat([numer_ger, cate_ger, ger[['Label']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1581f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X, y = scale_ger.loc[:, np.delete(scale_ger.columns.values, \n",
    "                                        np.where(scale_ger.columns.values == ['Label']))], \\\n",
    "        scale_ger.loc[:, 'Label']\n",
    "\n",
    "# train on randomForest to get important features\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                             random_state=0)\n",
    "clf.fit(X, y) \n",
    "\n",
    "feature_importances = pd.DataFrame(sorted(zip(scale_ger.columns, clf.feature_importances_), key=lambda x: x[1] * -1),\n",
    "                                    columns = ['feature','importance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d8a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  importance\n",
      "0       Status_A14    0.172064\n",
      "1       Status_A11    0.158938\n",
      "2         Duration    0.088689\n",
      "3      History_A34    0.077666\n",
      "4           Amount    0.070354\n",
      "..             ...         ...\n",
      "56   Property_A122    0.000000\n",
      "57        Job_A171    0.000000\n",
      "58        Job_A172    0.000000\n",
      "59        Job_A173    0.000000\n",
      "60  Telephone_A191    0.000000\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06fd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = feature_importances[feature_importances.importance>0]['feature'].values\n",
    "\n",
    "X, y = scale_ger.loc[:,top_features], scale_ger.loc[:,'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fed5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y*(-1)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "624e2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold,cross_val_score,StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9464e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0,stratify = y)\n",
    "sm = SMOTE(random_state=0,sampling_strategy=1)\n",
    "x_train_b, y_train_b = sm.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dfb4199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 560, 1: 560}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train_b, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc595813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score,make_scorer,confusion_matrix,brier_score_loss,accuracy_score\n",
    "from sklearn import metrics\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b520bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_stat(y, yhat):\n",
    "    return ks_2samp(yhat[y==1], yhat[y!=1]).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbdb9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type2_calcu(y,yhat):\n",
    "    confusion =confusion_matrix(y,yhat)\n",
    "    #[row, column]\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return FP / float(FP + TN)\n",
    "def type1_calcu(y,yhat):\n",
    "    confusion =confusion_matrix(y,yhat)\n",
    "    #[row, column]\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    return FN / float(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ae3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae01bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(model):\n",
    "    train=[]\n",
    "    test=[]\n",
    "    y_train_c=model.predict(x_train)\n",
    "    y_train_pre=model.predict_proba(x_train)\n",
    "    y_pred_c=model.predict(x_test)\n",
    "    y_pred = model.predict_proba(x_test)\n",
    "    #roc\n",
    "    train.append(roc_auc_score(y_train,y_train_pre[:,1]))\n",
    "    test.append(roc_auc_score(y_test, y_pred[:, 1]))\n",
    "    #ks\n",
    "    train.append(ks_stat(y_train,y_train_pre[:,1]))\n",
    "    test.append(ks_stat(y_test, y_pred[:, 1]))\n",
    "    #brier\n",
    "    train.append(brier_score_loss(y_train,y_train_pre[:,1]))\n",
    "    test.append(brier_score_loss(y_test, y_pred[:, 1]))\n",
    "    #acc\n",
    "    train.append(accuracy_score(y_train,y_train_c))\n",
    "    test.append(accuracy_score(y_test, y_pred_c))\n",
    "    #t1\n",
    "    train.append(type1_calcu(y_train,y_train_c))\n",
    "    test.append(type1_calcu(y_test, y_pred_c))\n",
    "    #t2\n",
    "    train.append(type2_calcu(y_train,y_train_c))\n",
    "    test.append(type2_calcu(y_test, y_pred_c))\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03403bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[x_train.columns.str.contains(\"[\\[\\]<]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f1728e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  svc , the best parameters:  {'C': 1, 'kernel': 'linear'}\n",
      "For  xgb , the best parameters:  {'learning_rate': 0.01, 'max_depth': 20, 'subsample': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.72982143        nan 0.7450744         nan 0.75199405\n",
      "        nan 0.75264881        nan 0.74822917        nan 0.74340774\n",
      "        nan 0.73846726        nan 0.73467262        nan 0.73293155\n",
      "        nan 0.73193452]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  LR , the best parameters:  {'C': 0.21544346900318834, 'penalty': 'l2'}\n",
      "For  DT , the best parameters:  {'max_depth': 4, 'min_samples_leaf': 7}\n",
      "For  RF , the best parameters:  {'max_depth': 14, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "For  nb , the best parameters:  {}\n",
      "                                                   0  \\\n",
      "0  [0.543921130952381, 0.11071428571428571, 0.208...   \n",
      "1  [0.9510565476190477, 0.7755952380952381, 0.140...   \n",
      "2  [0.8207514880952382, 0.5232142857142857, 0.151...   \n",
      "3  [0.7867745535714286, 0.43392857142857144, 0.16...   \n",
      "4  [0.9468824404761905, 0.7601190476190476, 0.116...   \n",
      "5  [0.780141369047619, 0.4928571428571429, 0.2309...   \n",
      "\n",
      "                                                   1  \n",
      "0  [0.5033333333333333, 0.09523809523809523, 0.21...  \n",
      "1  [0.8308333333333333, 0.4785714285714286, 0.170...  \n",
      "2  [0.8488095238095238, 0.5261904761904762, 0.144...  \n",
      "3  [0.729702380952381, 0.40476190476190477, 0.181...  \n",
      "4  [0.7726190476190476, 0.4642857142857143, 0.167...  \n",
      "5  [0.7148809523809525, 0.4357142857142857, 0.256...  \n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "xgb_params = {'learning_rate': [0.01],'max_depth': [10,20,40,50],'subsample': [0.5,0.7]}\n",
    "svc_params = {'kernel':['linear'], 'C':[1]}\n",
    "lr_params={'penalty':('l1','l2'),'C':np.logspace(-2,2,10,base=10)}\n",
    "dt_params={'max_depth':[2,4,6,8,10,12],'min_samples_leaf':[1,3,5,7]}\n",
    "rf_params={'max_depth': [2,8,10,14],'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators':[1,5,10,15,20]}\n",
    "nb_p={}\n",
    "models.append(('svc',svc_params,SVC(probability=True,max_iter=100)))\n",
    "models.append(('xgb',xgb_params,xgb.XGBClassifier()))\n",
    "models.append(('LR',lr_params,LogisticRegression()))\n",
    "models.append(('DT',dt_params,DecisionTreeClassifier()))\n",
    "models.append(('RF',rf_params,RandomForestClassifier()))\n",
    "models.append(('nb',nb_p,GaussianNB()))\n",
    "\n",
    "results=[]\n",
    "for model_name, parameters, model in models:\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=1234)\n",
    "    clf = GridSearchCV(model, parameters, cv=skf,scoring='roc_auc')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('For ',model_name,', the best parameters: ', clf.best_params_)\n",
    "    results.append(scores(clf))\n",
    "    \n",
    "results=pd.DataFrame(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94fd2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.543921130952381, 0.11071428571428571, 0.208...</td>\n",
       "      <td>[0.5033333333333333, 0.09523809523809523, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9510565476190477, 0.7755952380952381, 0.140...</td>\n",
       "      <td>[0.8308333333333333, 0.4785714285714286, 0.170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8207514880952382, 0.5232142857142857, 0.151...</td>\n",
       "      <td>[0.8488095238095238, 0.5261904761904762, 0.144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.7867745535714286, 0.43392857142857144, 0.16...</td>\n",
       "      <td>[0.729702380952381, 0.40476190476190477, 0.181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9468824404761905, 0.7601190476190476, 0.116...</td>\n",
       "      <td>[0.7726190476190476, 0.4642857142857143, 0.167...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  [0.543921130952381, 0.11071428571428571, 0.208...   \n",
       "1  [0.9510565476190477, 0.7755952380952381, 0.140...   \n",
       "2  [0.8207514880952382, 0.5232142857142857, 0.151...   \n",
       "3  [0.7867745535714286, 0.43392857142857144, 0.16...   \n",
       "4  [0.9468824404761905, 0.7601190476190476, 0.116...   \n",
       "\n",
       "                                                   c  \n",
       "0  [0.5033333333333333, 0.09523809523809523, 0.21...  \n",
       "1  [0.8308333333333333, 0.4785714285714286, 0.170...  \n",
       "2  [0.8488095238095238, 0.5261904761904762, 0.144...  \n",
       "3  [0.729702380952381, 0.40476190476190477, 0.181...  \n",
       "4  [0.7726190476190476, 0.4642857142857143, 0.167...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns=list('xc')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a71dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543921</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.208754</td>\n",
       "      <td>0.54750</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.212210</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.951057</td>\n",
       "      <td>0.775595</td>\n",
       "      <td>0.140162</td>\n",
       "      <td>0.89625</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.830833</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.170760</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.820751</td>\n",
       "      <td>0.523214</td>\n",
       "      <td>0.151799</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.848810</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>0.144182</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786775</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>0.161627</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.729702</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.181536</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.946882</td>\n",
       "      <td>0.760119</td>\n",
       "      <td>0.116073</td>\n",
       "      <td>0.85750</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.167753</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.780141</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.230911</td>\n",
       "      <td>0.72750</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.714881</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.256111</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2       x3        x4        x5        c0  \\\n",
       "0  0.543921  0.110714  0.208754  0.54750  0.410714  0.550000  0.503333   \n",
       "1  0.951057  0.775595  0.140162  0.89625  0.016071  0.308333  0.830833   \n",
       "2  0.820751  0.523214  0.151799  0.78250  0.098214  0.495833  0.848810   \n",
       "3  0.786775  0.433929  0.161627  0.75875  0.117857  0.529167  0.729702   \n",
       "4  0.946882  0.760119  0.116073  0.85750  0.016071  0.437500  0.772619   \n",
       "5  0.780141  0.492857  0.230911  0.72750  0.278571  0.258333  0.714881   \n",
       "\n",
       "         c1        c2     c3        c4        c5  \n",
       "0  0.095238  0.212210  0.555  0.392857  0.566667  \n",
       "1  0.478571  0.170760  0.790  0.064286  0.550000  \n",
       "2  0.526190  0.144182  0.800  0.064286  0.516667  \n",
       "3  0.404762  0.181536  0.720  0.150000  0.583333  \n",
       "4  0.464286  0.167753  0.740  0.092857  0.650000  \n",
       "5  0.435714  0.256111  0.700  0.300000  0.300000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_col(data, columns):\n",
    "    for c in columns:\n",
    "        new_col = data.pop(c)\n",
    "        max_len = max(list(map(len, new_col.values)))  # 最大长度\n",
    "        new_col = new_col.apply(lambda x: x + [None]*(max_len - len(x)))  # 补空值，None可换成np.nan\n",
    "        new_col = np.array(new_col.tolist()).T  # 转置\n",
    "        for i, j in enumerate(new_col):\n",
    "            data[c + str(i)] = j\n",
    "\n",
    "\n",
    "split_col(results, columns=['x','c'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b792aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['train_auc','train_k-s','train_brier','train_acc','train_t1','train_t2','test_auc','test_k-s','test_brier','test_acc','test_t1','test_t2']\n",
    "results.columns=colnames\n",
    "results.to_csv(\"unbalanced-ger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97a23e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train_b\n",
    "y_train=y_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a127dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  svc , the best parameters:  {'C': 1, 'kernel': 'linear'}\n",
      "For  xgb , the best parameters:  {'learning_rate': 0.01, 'max_depth': 20, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.82661352        nan 0.85100765        nan 0.86830357\n",
      "        nan 0.87719388        nan 0.88105867        nan 0.88235969\n",
      "        nan 0.88326531        nan 0.88343112        nan 0.88360332\n",
      "        nan 0.88233418]\n",
      "  warnings.warn(\n",
      "/Users/weixiao/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  LR , the best parameters:  {'C': 35.93813663804626, 'penalty': 'l2'}\n",
      "For  DT , the best parameters:  {'max_depth': 6, 'min_samples_leaf': 7}\n",
      "For  RF , the best parameters:  {'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 15}\n",
      "For  nb , the best parameters:  {}\n",
      "                                                   0  \\\n",
      "0  [0.6118686224489797, 0.1982142857142857, 0.244...   \n",
      "1  [0.9843654336734695, 0.8946428571428572, 0.108...   \n",
      "2  [0.9206760204081633, 0.6946428571428571, 0.110...   \n",
      "3  [0.8931967474489796, 0.6303571428571428, 0.128...   \n",
      "4  [0.9973501275510204, 0.95, 0.04921224085127885...   \n",
      "5  [0.8483928571428572, 0.6035714285714285, 0.221...   \n",
      "\n",
      "                                                   1  \n",
      "0  [0.4945833333333333, 0.09047619047619047, 0.24...  \n",
      "1  [0.8241666666666666, 0.5023809523809524, 0.171...  \n",
      "2  [0.8061904761904762, 0.5, 0.1575009341761698, ...  \n",
      "3  [0.7363095238095239, 0.4642857142857143, 0.187...  \n",
      "4  [0.8213690476190476, 0.5166666666666667, 0.160...  \n",
      "5  [0.6817857142857142, 0.3619047619047619, 0.306...  \n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "xgb_params = {'learning_rate': [0.01],'max_depth': [10,20,40,50],'subsample': [0.5,0.7]}\n",
    "svc_params = {'kernel':['linear'], 'C':[1]}\n",
    "lr_params={'penalty':('l1','l2'),'C':np.logspace(-2,2,10,base=10)}\n",
    "dt_params={'max_depth':[2,4,6,8,10,12],'min_samples_leaf':[1,3,5,7]}\n",
    "rf_params={'max_depth': [2,8,10,14],'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators':[1,5,10,15,20]}\n",
    "nb_p={}\n",
    "models.append(('svc',svc_params,SVC(probability=True,max_iter=100)))\n",
    "models.append(('xgb',xgb_params,xgb.XGBClassifier()))\n",
    "models.append(('LR',lr_params,LogisticRegression()))\n",
    "models.append(('DT',dt_params,DecisionTreeClassifier()))\n",
    "models.append(('RF',rf_params,RandomForestClassifier()))\n",
    "models.append(('nb',nb_p,GaussianNB()))\n",
    "\n",
    "results=[]\n",
    "for model_name, parameters, model in models:\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=1234)\n",
    "    clf = GridSearchCV(model, parameters, cv=skf,scoring='roc_auc')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('For ',model_name,', the best parameters: ', clf.best_params_)\n",
    "    results.append(scores(clf))\n",
    "    \n",
    "results=pd.DataFrame(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c40f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=list('xc')\n",
    "split_col(results, columns=['x','c'])\n",
    "colnames=['train_auc','train_k-s','train_brier','train_acc','train_t1','train_t2','test_auc','test_k-s','test_brier','test_acc','test_t1','test_t2']\n",
    "results.columns=colnames\n",
    "results.to_csv(\"balanced-ger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633baeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
